{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=banner.png>\n",
    "\n",
    "# <a name=\"0\">Measuring and Mitigating Toxicity in Large Language Models</a>\n",
    "\n",
    "Building and operating machine learning applications responsibly requires an active, consistent approach to prevent, assess, and mitigate harm. This workshop gives you hands-on experience to identify toxicity in LLM output and to mitigate and reduce toxicity.\n",
    "\n",
    "In this workshop you will:\n",
    "1. <a href=\"#1\">Define the problem:</a> load a dataset and look at examples\n",
    "2. <a href=\"#2\">Explore the starting toxicity:</a> format data and apply a classifier\n",
    "3. <a href=\"#3\">Use a LLM to generate summaries:</a> load the model, create prompts, explore output\n",
    "4. <a href=\"#4\">Evaluate summaries for toxicity:</a> apply the toxicity classifier, compare toxicity values\n",
    "5. <a href=\"#5\">Mitigate toxicity using guardrails:</a> hide unwanted words and filter profanity\n",
    "\n",
    "**Runtime**\n",
    "\n",
    "This notebook takes about 90 minutes to complete (using some inbuilt shortcuts).\n",
    "\n",
    "**Kernel Selection**\n",
    "\n",
    "By default, the notebook will open with the correct image and kernel. If prompted to select a kernel, choose the image `PyTorch 2.0.1 Python 3.10`, kernel `Python 3`, and instance `ml.g4dn.2xlarge`.\n",
    "\n",
    "<div style=\"text-align: center;\"><img src=\"kernel.png\" alt=\"select the PyTorch 2.0.1 Python3.10 image, Python 3 kernel, and ml.g4dn.2xlarge instance type.\" border=1 width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "**Cells and Sections**\n",
    "\n",
    "This notebook includes *markdown cells* with instructions for you to read, and *code cells* for you to edit and run. To run a code cell, click on the cell and type `Shift+Enter` on your keyboard. The cell will execute and any output will appear in the notebook, just below the cell.\n",
    "\n",
    "Some cells take time to run. An asterisk `[*]` next to the cell means it is still running. A number `[1]` next to the cell shows you the order in which the cells were executed.\n",
    "\n",
    "Each section of the notebook is self-contained. To start in the middle, catch up, or recover from a runtime error, you can start at the beginning of any section, where shortcut functions will load the data and models needed to continue.\n",
    "\n",
    "**OutOfMemoryError**\n",
    "\n",
    "This notebook is memory-intensive. Run cleanup cells at the end of each section. If you see an OutOfMemoryError, just restart your kernel and jump back into the notebook at the beginning of your current section.\n",
    "\n",
    "To check the available memory at any time, run a code cell with this command `!nvidia-smi`\n",
    "\n",
    "**Content Warning**\n",
    "\n",
    "This notebook surfaces toxic content in an existing dataset and may generate new toxic or harmful content. Please be mindful of your mental health, emotional health, and safety. \n",
    "\n",
    "If you're joining us at a live workshop, support staff are here to help you with technical challenges, answer questions, and help you get the most out of the workshop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercises</b>: Work at your own pace, and pause when you reach an Exercise. We will regroup for discussion at each Exercise before moving to the next section.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "Select the default image (PyTorch 2.0.1 Python 3.10 GPU Optimized) and kernel (Python 3) in your notebook instance.\n",
    "\n",
    "\n",
    "\n",
    "Next, upgrade [pip](https://pypi.org/project/pip/) (a Python package management system) and install all required libraries from the provided requirements.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "# This takes about 1 minute to run\n",
    "!pip install -q -U pip --root-user-action=ignore \n",
    "!pip3 install -q -r requirements.txt --root-user-action=ignore\n",
    "!python3 -m spacy download en_core_web_sm -q --root-user-action=ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "import transformers, torch\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "from tqdm.auto import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"1\">1. Define the Problem</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Your team is developing a film summarization feature that helps customers to quickly find a film they want to watch. Given a transcript of the film, your system will produce a short summary. You plan to use Generative AI for this problem, but you know that large language models can sometimes produce undesirable output. \n",
    "\n",
    "<b>Your task is to use a pre-trained large language model to produce film summaries, measure the toxicity present in the summaries, and mitigate this toxicity using guardrail filters.</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1\">1.1. Load a dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "The first step is to understand your data. \n",
    "\n",
    "In this notebook, the \"[Cornell Movie-Dialogs Corpus](https://convokit.cornell.edu/documentation/movie.html)\" will serve as your film database. This corpus is a large metadata-rich collection of fictional conversations extracted from raw movie scripts. The dataset contains 220,579 conversational exchanges between 10,292 pairs of movie characters in 617 movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.data_utils import _prepare_data\n",
    "\n",
    "# Load the data. Takes about 1 minute\n",
    "movie_df = _prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Look at some examples\n",
    "First, look at the structure. We have movie titles, the full text script (\"dialogue\"), and a genre for every movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at the first 2 rows of data\n",
    "movie_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 18 genres. We will focus on two of the most common: action and comedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List the available genres\n",
    "movie_df[\"genre\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, have a look at some text snippets from action and comedy films. The cell below will return different examples every time you run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.data_utils import _explore_genres\n",
    "\n",
    "# View a random sample from several genres in the dataset. Run this cell multiple times to view different examples.\n",
    "_explore_genres(movie_df, [\"action\", \"comedy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercise 1</b>: Edit the code block above to explore other film genres. What do you notice in these snippets? Does one genre use more explicit language than another? How do these differences confirm or contradict your expectations?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This cell is for you! Double-click to edit. Write your notes or answers to the exercise here.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"2\">2. Explore the starting toxicity</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now that you have examined your data, you can reformat it and apply a toxicity classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2.1\">2.1 Format data for processing</a>\n",
    "\n",
    "Machine learning models, including LLMs and toxicity classifiers, require the data to be stored in a specific format. Use the [HuggingFace ðŸ¤— Datasets](https://huggingface.co/docs/datasets/index) library to convert the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you're continuing from Section 1, skip this cell.\n",
    "\n",
    "# Shortcut: If you're starting from Section 2, load your data now. It takes a minute.\n",
    "from utils.data_utils import _prepare_data\n",
    "\n",
    "movie_df = _prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# convert the data\n",
    "movie_dataset = Dataset.from_pandas(movie_df)\n",
    "\n",
    "# show the data\n",
    "movie_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can see that there are 617 distinct movies. To move through the remainder of the notebook more quickly, select the first 200 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select a sample of 200\n",
    "dataset = movie_dataset.select(range(200))\n",
    "\n",
    "# save the dataset to disk\n",
    "dataset.save_to_disk(\"movie_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Apply a toxicity classifier</a>\n",
    "\n",
    "The <a href=\"https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target\">LFTW R4 Target model</a> is a hate speech detector based on the <a href=\"https://arxiv.org/abs/1907.11692\">RoBERTa</a> architecture and trained on <a href=\"https://allenai.org/data/real-toxicity-prompts\">RealToxicityPrompts</a>. This classifier is publicly available and easy to use on a HuggingFace ðŸ¤— dataset like the one we just created.\n",
    "\n",
    "Let's explore the toxicity of our dataset according to this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.eval_utils import _add_toxicty_column\n",
    "\n",
    "# Calculate toxicity of the dialogue in each film, using LFTW R4. Add toxicity as a column to our dataset.\n",
    "dataset = _add_toxicty_column(dataset, \"dialogue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# View the toxicity of the full dataset\n",
    "print(\"overall toxicity \", np.mean(dataset[\"toxicity_score\"]))\n",
    "\n",
    "# View the toxicity of several genres of data\n",
    "print(\n",
    "    \"action toxicity: \",\n",
    "    np.mean(\n",
    "        dataset.filter(lambda example: example[\"genre\"] == \"action\")[\"toxicity_score\"]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"comedy toxicity: \",\n",
    "    np.mean(\n",
    "        dataset.filter(lambda example: example[\"genre\"] == \"comedy\")[\"toxicity_score\"]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As you can see, the acton genre text is showing higher toxicity compared to comedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercise 2</b>: Add code that calculates the toxicity for more genres in the cell below. Do you agree with these toxicity judgments? Does LFTW R4 toxicity confirm or contradict your impression of toxicity in Exercise 1? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### complete your code here #####\n",
    "\n",
    "\n",
    "###################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Delete old objects with `del`.\n",
    "del movie_dataset, movie_df, dataset\n",
    "\n",
    "# Release memory after deleting objects.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Conclusion</b>: In this section, you loaded a movie transcript dataset and converted it into a HuggingFace Dataset object. Then you applied the LFTW R4 toxicity classifier to explore the toxicity of the source data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"3\">3. Load and use a Large Language Model</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[T5 (Text-To-Text Transfer Transformer)](https://github.com/google-research/text-to-text-transfer-transformer) is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks. T5 works well on a variety of tasks out-of-the-box by prepending a different prefix to the input corresponding to each task. Tasks include machine translation, **document summarization**, question answering, and classification (e.g., sentiment analysis). \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://camo.githubusercontent.com/623b4dea0b653f2ad3f36c71ebfe749a677ac0a1/68747470733a2f2f6d69726f2e6d656469756d2e636f6d2f6d61782f343030362f312a44304a31674e51663876727255704b657944387750412e706e67\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "For more details have a look at the T5 documentation on HuggingFace ðŸ¤— [here](https://huggingface.co/docs/transformers/model_doc/t5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Load the T5 model\n",
    "\n",
    "First, download the T5 model using the `T5ForConditionalGeneration` class provided by the [HuggingFace ðŸ¤— transformers library](https://github.com/huggingface/transformers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# load the model with GPU as the preferred device type\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"google/flan-t5-large\",\n",
    "    device_map={\"\": 0},  # this will load the model in GPU\n",
    "    torch_dtype=torch.float32,\n",
    "    return_dict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Create a prompt\n",
    "Let's create a prompt by joining an instruction to summarize text with the actual movie script.\n",
    "\n",
    "LLM prompts can be very elaborate, as ultimately the prompt is the only input the LLM sees - the better the prompt, the better the result. \n",
    "\n",
    "Each LLM may have its own prompting requirements. In the case of T5, the summarization prompts used for pre-training all included the keyword *summarize*, so you should use that in your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the dataset you created in Section 1\n",
    "dataset = load_from_disk(\"movie_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a prompt for the item at index [nth] from dataset.\n",
    "def get_inference_prompt(dataset, nth):\n",
    "    \"\"\" \"Return a LLM summarization prompt for the nth item in dataset.\"\"\"\n",
    "    inference_prompt = (\n",
    "        \"Summarize the following conversation from a movie script:  \\n\\n'''%s'''\"\n",
    "        % dataset[nth][\"dialogue\"]\n",
    "    )\n",
    "    return inference_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print out the prompt for one item in the dataset. The full prompot includes the entire script, so just print the first 235 characters.\n",
    "inference_prompt = get_inference_prompt(dataset, 0)\n",
    "print(inference_prompt[:235])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Tokenize LLM inputs\n",
    "\n",
    "This plain-text version of the prompt is easy for humans to read. But before this prompt can be processed by T5, it gets converted into *tokens*.  \n",
    "\n",
    "Initialize an instance of `AutoTokenizer` to use with your T5 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer_t5 = AutoTokenizer.from_pretrained(\n",
    "    \"google/flan-t5-large\",\n",
    "    skip_special_tokens=True,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    use_fast=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the tokenized version of the prompt you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tokenizer_t5(inference_prompt[:235]).input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The number of tokens passed to an LLM through the tokenizer should not be greater than the number of tokens used in pre-training**. T5 was pre-trained using 512 input tokens, and with `truncation=True` in our tokenizer, all text beyond 512 tokens will be truncated.\n",
    "\n",
    "For English, 1 token is approximately 4 characters or 0.75 words, so this tokenizer will cut off our movie scripts at around 385 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Use T5 to generate a movie summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a summary with T5 you need an inference pipeline:\n",
    "\n",
    "    Encode the input (tokenization) -> Pass the tokens through the model -> Decode model outputs back to text\n",
    "\n",
    "Now that `tokenizer_t5` and `model_t5` are initialized, you can execute this pipeline and produce film summaries ðŸ¥³\n",
    "\n",
    "\n",
    "Try it out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.model_utils import _generate_summary, _format_llm_output\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "def inference_pipeline(dataset, nth):\n",
    "    \"\"\"Run inference pipeline to generate a summary of the nth item in the dataset and return the formatted result.\"\"\"\n",
    "    print(\"Title: \", dataset[nth][\"movie\"], \"\\nGenre: \", dataset[nth][\"genre\"])\n",
    "    print(\"Summary:\")\n",
    "    return _format_llm_output(\n",
    "        _generate_summary(get_inference_prompt(dataset, nth), model_t5, tokenizer_t5)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the pipeline on one film from the database\n",
    "inference_pipeline(dataset, 199)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Compare summaries for truncated and chunked input\n",
    "\n",
    "You may notice that important plot points and characters from these movies are missing from their summaries. This is due to the 512 token limit described above. Only the first 512 tokens (~385 words) of the script were used to generate this summary.\n",
    "\n",
    "We can work around the token limit using *chunking*. This means splitting the movie transcript into smaller chunks, and summarizing chunks one by one. Finally, the smaller summaries are recombined for a final output. An important first step before splitting the transcript is teaching the model the vocubarly of the movie scripts by resizing the embedding space; this is where toxicity can easily enter a model.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"map_chain.png\" width=\"900\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a dataset with summaries that were produced using chunking.\n",
    "summaries = load_dataset(\"csv\", data_files=\"summaries_dataset.csv\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a summary using the original inference pipeline\n",
    "inference_pipeline(dataset, 199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare to the summary that uses chunking\n",
    "summary = summaries.filter(lambda example: example[\"movie\"] == (\"harold and maude\"))\n",
    "_format_llm_output(summary[\"summary\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercise 3</b>: Use the inference pipeline to generate more summaries in the code cells below. You can also explore more summaries that use chunking. How does the language in the summary look different from the language in the scripts from Exercise 1? Do you see any differences in the style, or in the amount of toxic language?    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### complete your code here #####\n",
    "\n",
    "# Generate a summary for a different movie, using the original inference pipeline\n",
    "\n",
    "# Note: there are 200 items in your datset. The first item has index 0. The last item has index 199.\n",
    "\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### complete your code here #####\n",
    "\n",
    "# Compare to the summary that uses chunking, for the same movie\n",
    "\n",
    "###################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, delete the prompts that were used for inference; e.g. <code>del inference_prompt</code> and also clear the instance memory with <code>gc.collect()</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del inference_prompt, summaries, inference_pipeline, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Conclusion</b>: At this point, you have summaries for all the movies and it is time to check whether those summaries contain any hate speech, slurs or toxic remarks. You may expect the toxicity values in a summarization task to be low unless the text being summarised itself already contains toxic speech. However the model may amplify toxicity that is present in the input data, leading to higher toxicity in the summaries, compared to the LLM inputs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"4\"> 4. Evaluate LLM-generated summaries for toxicity</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Section 2, you used the LFTW R4 model to measure toxicity in movie scripts. In Section 3, you used these scripts as input to the T5 LLM to generate summaries.\n",
    "\n",
    "In this section, you will apply LFTW R4 to the LLM output, to see how toxicity in the inputs may have been amplified by the language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.1. Compare input toxicity to output toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from utils.eval_utils import _add_toxicty_column\n",
    "import numpy as np\n",
    "\n",
    "# Calculate toxicity of the dialogue in each film, using LFTW R4. Add toxicity as a column to our dataset\n",
    "dataset = load_from_disk(\"movie_dataset\")\n",
    "dataset = _add_toxicty_column(dataset, \"dialogue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For reference: review the overall toxicity of the input data\n",
    "print(\"overall toxicity \", np.mean(dataset[\"toxicity_score\"]))\n",
    "\n",
    "# For reference: review the toxicity of the action and comedy genres\n",
    "print(\n",
    "    \"action toxicity: \",\n",
    "    np.mean(\n",
    "        dataset.filter(lambda example: example[\"genre\"] == \"action\")[\"toxicity_score\"]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"comedy toxicity: \",\n",
    "    np.mean(\n",
    "        dataset.filter(lambda example: example[\"genre\"] == \"comedy\")[\"toxicity_score\"]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the toxicity of the summaries. Add toxicity as a column to the summaries dataset\n",
    "summaries_dataset = load_dataset(\n",
    "    \"csv\", data_files=\"summaries_dataset.csv\", split=\"train\"\n",
    ")\n",
    "summaries_dataset = _add_toxicty_column(summaries_dataset, \"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare to the overall toxicity of the summaries\n",
    "print(\"overall toxicity \", np.mean(summaries_dataset[\"toxicity_score\"]))\n",
    "\n",
    "# Compare to the toxicity of action summaries and comedy summaries\n",
    "print(\n",
    "    \"mean action toxicity: \",\n",
    "    np.mean(\n",
    "        summaries_dataset.filter(lambda example: example[\"genre\"] == \"action\")[\n",
    "            \"toxicity_score\"\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"mean comedy toxicity: \",\n",
    "    np.mean(\n",
    "        summaries_dataset.filter(lambda example: example[\"genre\"] == \"comedy\")[\n",
    "            \"toxicity_score\"\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.2. Compare mean toxicity to max toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean toxicity of a dataset, or of a genre, can sometimes mask the true impact of toxicity in that data.\n",
    "\n",
    "Compare the mean toxicity to the maximum toxicity in our two focus genres: comedy and action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"max action toxicity: \",\n",
    "    np.max(\n",
    "        summaries_dataset.filter(lambda example: example[\"genre\"] == \"action\")[\n",
    "            \"toxicity_score\"\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"max comedy toxicity: \",\n",
    "    np.max(\n",
    "        summaries_dataset.filter(lambda example: example[\"genre\"] == \"comedy\")[\n",
    "            \"toxicity_score\"\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Compare high-toxicity outputs to low-toxicity outputs\n",
    "\n",
    "<i class=\"fas fa-exclamation-triangle\" style=\"color: #ea0606;\"></i> **Content Warning** <i class=\"fas fa-exclamation-triangle\" style=\"color: #ea0606;\"></i> These summaries contain explicit profanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.model_utils import _format_llm_output\n",
    "\n",
    "toxic_summaries = summaries_dataset.filter(lambda example: example[\"toxicity_score\"] > 0.95)\n",
    "\n",
    "# There are 9 of these, starting with 0. \n",
    "toxic_id = 1\n",
    "print(\"**Toxic summary**\")\n",
    "print(\"Title:\", toxic_summaries[\"movie\"][toxic_id])\n",
    "print(\"Genre:\", toxic_summaries[\"genre\"][toxic_id])\n",
    "_format_llm_output(toxic_summaries[\"summary\"][toxic_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benign_summaries = summaries_dataset.filter(lambda example: example[\"toxicity_score\"] < 0.05)\n",
    "\n",
    "# There are 113 of these, starting with 0.\n",
    "benign_id = 112\n",
    "print(\"**Benign summary**\")\n",
    "print(\"Title:\", benign_summaries[\"movie\"][benign_id])\n",
    "print(\"Genre:\", benign_summaries[\"genre\"][benign_id])\n",
    "_format_llm_output(benign_summaries[\"summary\"][benign_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercise 4</b>: Edit the toxic_id and benign_id above, to explore more summaries. Why is the max toxicity similar in these two genres, when the mean toxicity is very different? What is the impact of maximum and mean toxicity on customers who use your summarization feature?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This cell is for you! Double-click to edit. Write your notes or answers to the exercise here.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.4. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del summaries_dataset, dataset\n",
    "import gc, torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Conclusion</b>: We have seen that some summaries are toxic and would like to remediate this. The first option to mitigate toxicity would be to use a protective wrapper around the LLM itself. This is called a guardrail and is a very useful technique to employ whenever you don't have access to the model itself, or you lack sufficient time or compute resources to make any modifications to the LLM. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"5\"> 5. Mitigate toxicity using Guardrails</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "In this section you will explore coding examples for *guardrails*. These are post-processing tools that can filter certain keywords or that leverage metrics to decide if content is harmful. \n",
    "\n",
    "**Setup:** First, restart your kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.get_ipython().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Guardrails from a keyword list\n",
    "\n",
    "The first guardrail you will try is a filter based on a fixed list of keywords.\n",
    "\n",
    "\n",
    "To get ready, reload your data and model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "movie_dataset = load_from_disk(\"movie_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.1.1. Create a Validator from a word list\n",
    "\n",
    "Next you will use this list to build a guardrail using [Guardrails.ai](https://docs.guardrailsai.com/). First, you need a `Validator` to check for blocked words and define what happens when a blocked word is seen.\n",
    "\n",
    "In the first `Validator`, you will make a list of words to block, and apply this to all summaries. Start with something simple that you have seen in LLM-generated summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from guardrails.validators import *\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "# provide a name for the validator to use in the RAIL spec later\n",
    "@register_validator(name=\"is-keyword-free\", data_type=\"string\")\n",
    "class IsKeywordFree(Validator):\n",
    "    # the Validator class needs to contain a validate method\n",
    "    def validate(self, value: Any, metadata: Dict) -> ValidationResult:\n",
    "        \n",
    "        # set up a list of forbidden words\n",
    "        kw_list = [\"Bitch\"]\n",
    "\n",
    "        # check for these forbidden words in the current string\n",
    "        if any(kw in value for kw in kw_list):\n",
    "            # replace forbidden words in output with ***\n",
    "            for kw in kw_list:\n",
    "                censored_text = value.replace(kw, \"***\")\n",
    "            # display error message and return the fix value\n",
    "            return FailResult(\n",
    "                error_message=f\"Expression '{value}' contains forbidden keyword.\",\n",
    "                fix_value=censored_text,\n",
    "            )\n",
    "        # else return pass\n",
    "        return PassResult()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This validator checks for words from our keyword list, and replaces them with the string `***`. \n",
    "\n",
    "In the `validate` method, you can check whether values are in a certain range, or check for keywords as our example shows. You can also define a corrective action to take, such as hiding problematic parts or refusing to create an output altogether. \n",
    "\n",
    "A full overview of all the possible corrective actions can be found [here](https://docs.guardrailsai.com/concepts/output/#specifying-corrective-actions).\n",
    "\n",
    "### 5.1.2. Create a guardrail from your Validator\n",
    "\n",
    "Once you have a validator, you pass it to a guard object using a `RAIL spec` (Reliable AI markup Language specification). This is an XML file that specifies the validator you want to use and creates a placeholder for the prompt to pass through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.data_utils import _get_keyword_free_spec\n",
    "\n",
    "# import rail spec to use\n",
    "rail_str = _get_keyword_free_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import guardrails as gd\n",
    "\n",
    "# create a Guard object from the above RAIL string\n",
    "guard = gd.Guard.from_rail_string(rail_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3. Apply your guardrail to LLM output\n",
    "\n",
    "Finally, pass the movie dialogue you want summarized and checked with the guardrail to the Guard object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.model_utils import _my_llm_api\n",
    "\n",
    "# This takes a few seconds to instantiate the model and run inference.\n",
    "\n",
    "# Generate an LLM response, wrapped in a guardrail filter.\n",
    "raw_llm_response, validated_response = guard(\n",
    "    llm_api=_my_llm_api,\n",
    "    prompt_params={\"statement_to_be_summarized\": movie_dataset[0][\"dialogue\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show the output.\n",
    "print(f\"Original Output: {raw_llm_response}\\n\")\n",
    "print(f\"Validated Output: {validated_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Guardrails from a profanity classifier\n",
    "\n",
    "It may be difficult to make a list that covers all of the words we want to block. Instead of using a pre-defined keyword list, you can use a classifier to determine if a word is acceptable or not. Next, you will apply a pre-trained profanity classifier to determine if a word should be blocked by your guardrail.\n",
    "\n",
    "You can also try a different corrective action. Instead of fixing the output string, the guardrail can block the entire output.\n",
    "\n",
    "\n",
    "### 5.2.1. Create the Validator and guardrail objects\n",
    "\n",
    "Start with a new `Validator` object that uses the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from profanity_check import predict\n",
    "\n",
    "\n",
    "@register_validator(name=\"is-profanity-free\", data_type=\"string\")\n",
    "class IsProfanityFree(Validator):\n",
    "    def validate(self, value: Any, metadata: Dict) -> ValidationResult:\n",
    "        prediction = predict([value])\n",
    "        if prediction[0] == 1:\n",
    "            return FailResult(\n",
    "                error_message=f\"The result contains profanity and will be filtered.\",\n",
    "                fix_value=\"\",\n",
    "            )\n",
    "        return PassResult()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass this validator into your guard object using a new rail string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.data_utils import _get_metric_spec\n",
    "\n",
    "# import the rail spec to use\n",
    "rail_str = _get_metric_spec()\n",
    "\n",
    "# create a Guard object from the above RAIL string\n",
    "guard = gd.Guard.from_rail_string(rail_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Apply the new guardrail to LLM output\n",
    "\n",
    "To demonstrate the profanity filter, you can try to summarize something with more starting toxicity. \n",
    "\n",
    "In this step, you will use the LLM to summarize a reddit post. \n",
    "\n",
    "<i class=\"fas fa-exclamation-triangle\" style=\"color: #ea0606;\"></i> **Content Warning** <i class=\"fas fa-exclamation-triangle\" style=\"color: #ea0606;\"></i> This summary contains explicit profanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab a test string with more profanities, to test our classifier and filter\n",
    "from utils.data_utils import _reddit_test_string\n",
    "\n",
    "# This takes several seconds, to instantiate the model and perform inference.\n",
    "\n",
    "# Generate an LLM response, wrapped in a guardrail filter.\n",
    "raw_llm_response, validated_response = guard(\n",
    "    llm_api=_my_llm_api,\n",
    "    prompt_params={\"statement_to_be_summarized\": _reddit_test_string},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the output. Validated output should be empty, if the profanity filter worked.\n",
    "\n",
    "print(f\"Original Output: {raw_llm_response}\\n\")\n",
    "print(f\"Validated Output: {validated_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3. Explore the input, output, and validated output\n",
    "\n",
    "The Guardrails library also provides a visual overview of what the prompt, raw LLM output and validated output look like. \n",
    "\n",
    "Thanks to the guardrail, the validated output is empty.\n",
    "\n",
    "<i class=\"fas fa-exclamation-triangle\" style=\"color: #ea0606;\"></i> **Content Warning** <i class=\"fas fa-exclamation-triangle\" style=\"color: #ea0606;\"></i> This summary contains explicit profanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "guard.state.most_recent_call.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercise 5</b>: Did your guardrails work? Would you use this type of filter on the entire movie dataset? Why or why not? What are the strengths of a guardrail based on keywords? What are the weaknesses? Would these filters work on a different dataset?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*This cell is for you! Double-click to edit. Write your notes or answers to the exercise here.* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Conclusion</b>: You have seen guardrails as very effective and lightweight method to mitigate toxic outputs by adding a validation layer around the call to the LLM. Guardrails should be used whenever you are looking for a solution that does not require retraining the LLM itself.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!\n",
    "\n",
    "If you're joining us live, please don't forget the <mark>in-app survey</mark>. Thanks for your time and see you at the next workshop!"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.1 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.0.1-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
